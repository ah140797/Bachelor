{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8aaf76e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import(\n",
    " SGDRegressor,\n",
    " SGDClassifier,\n",
    " LinearRegression\n",
    ")\n",
    "\n",
    "from sklearn.ensemble import(\n",
    "    AdaBoostRegressor,\n",
    "    BaggingRegressor\n",
    ")\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    KFold,\n",
    "    StratifiedKFold,\n",
    "    GroupKFold,\n",
    "    RepeatedStratifiedKFold,\n",
    "    cross_val_score,\n",
    "    permutation_test_score,\n",
    "    GroupShuffleSplit,\n",
    ")\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector\n",
    "from scipy.stats import sem\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7b9b09ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we load the different datasets from the folder data/lexicon_analysi\n",
    "df = pd.read_csv('Data/lexicon_analysis/word_diff_emotion_raw_scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e3a41c58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Word</th>\n",
       "      <th>Group</th>\n",
       "      <th>proportion_diff_depr</th>\n",
       "      <th>proportion_diff_anx</th>\n",
       "      <th>anger</th>\n",
       "      <th>anticipation</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>trust</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>accident</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.019615</td>\n",
       "      <td>0.005814</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>accordion</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.094475</td>\n",
       "      <td>-0.086865</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>actor</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.068694</td>\n",
       "      <td>-0.081373</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>advantage</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001539</td>\n",
       "      <td>0.036491</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>advice</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.074927</td>\n",
       "      <td>-0.020681</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>383</td>\n",
       "      <td>worth</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.012449</td>\n",
       "      <td>-0.039607</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>384</td>\n",
       "      <td>year</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.039544</td>\n",
       "      <td>-0.004483</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>385</td>\n",
       "      <td>yellow</td>\n",
       "      <td>5</td>\n",
       "      <td>0.008325</td>\n",
       "      <td>0.046420</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>386</td>\n",
       "      <td>zone</td>\n",
       "      <td>2</td>\n",
       "      <td>0.018780</td>\n",
       "      <td>-0.000138</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>387</td>\n",
       "      <td>zoo</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.043055</td>\n",
       "      <td>-0.034761</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>387 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0       Word  Group  proportion_diff_depr  proportion_diff_anx  \\\n",
       "0             1   accident      7             -0.019615             0.005814   \n",
       "1             2  accordion      4             -0.094475            -0.086865   \n",
       "2             3      actor      8             -0.068694            -0.081373   \n",
       "3             4  advantage      1              0.001539             0.036491   \n",
       "4             5     advice      7             -0.074927            -0.020681   \n",
       "..          ...        ...    ...                   ...                  ...   \n",
       "382         383      worth      3             -0.012449            -0.039607   \n",
       "383         384       year      2             -0.039544            -0.004483   \n",
       "384         385     yellow      5              0.008325             0.046420   \n",
       "385         386       zone      2              0.018780            -0.000138   \n",
       "386         387        zoo      4             -0.043055            -0.034761   \n",
       "\n",
       "     anger  anticipation  disgust  fear  joy  negative  positive  sadness  \\\n",
       "0        0             0        0     1    0         1         0        1   \n",
       "1        0             0        0     0    0         0         0        0   \n",
       "2        0             0        0     0    0         0         0        0   \n",
       "3        0             0        0     0    0         0         1        0   \n",
       "4        0             0        0     0    0         0         0        0   \n",
       "..     ...           ...      ...   ...  ...       ...       ...      ...   \n",
       "382      0             0        0     0    0         0         1        0   \n",
       "383      0             0        0     0    0         0         0        0   \n",
       "384      0             0        0     0    0         0         0        0   \n",
       "385      0             0        0     0    0         0         0        0   \n",
       "386      0             0        0     0    0         0         0        0   \n",
       "\n",
       "     surprise  trust  \n",
       "0           1      0  \n",
       "1           0      0  \n",
       "2           0      0  \n",
       "3           0      0  \n",
       "4           0      1  \n",
       "..        ...    ...  \n",
       "382         0      0  \n",
       "383         0      0  \n",
       "384         0      0  \n",
       "385         0      0  \n",
       "386         0      0  \n",
       "\n",
       "[387 rows x 15 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6c5187",
   "metadata": {},
   "source": [
    "# Holdout Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b47bbc71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     anger  disgust  fear  joy  sadness  surprise  trust\n",
      "0        0        0     1    0        1         1      0\n",
      "4        0        0     0    0        0         0      1\n",
      "5        1        0     1    0        0         0      0\n",
      "7        0        0     0    0        0         0      0\n",
      "8        0        0     0    0        0         0      0\n",
      "..     ...      ...   ...  ...      ...       ...    ...\n",
      "379      0        0     0    0        0         0      1\n",
      "382      0        0     0    0        0         0      0\n",
      "383      0        0     0    0        0         0      0\n",
      "384      0        0     0    0        0         0      0\n",
      "385      0        0     0    0        0         0      0\n",
      "\n",
      "[242 rows x 7 columns]      anger  disgust  fear  joy  sadness  surprise  trust\n",
      "1        0        0     0    0        0         0      0\n",
      "2        0        0     0    0        0         0      0\n",
      "3        0        0     0    0        0         0      0\n",
      "6        0        0     0    0        0         0      1\n",
      "15       0        0     0    0        0         0      0\n",
      "..     ...      ...   ...  ...      ...       ...    ...\n",
      "371      0        0     1    0        0         1      0\n",
      "376      0        0     0    0        0         0      0\n",
      "380      0        1     1    0        1         0      0\n",
      "381      0        0     0    0        0         0      0\n",
      "386      0        0     0    0        0         0      0\n",
      "\n",
      "[145 rows x 7 columns]      Group  proportion_diff_depr  proportion_diff_anx\n",
      "0        7             -0.019615             0.005814\n",
      "4        7             -0.074927            -0.020681\n",
      "5        2             -0.069731            -0.080595\n",
      "7        5              0.099540             0.069467\n",
      "8        6              0.021850            -0.012616\n",
      "..     ...                   ...                  ...\n",
      "379      2             -0.017623            -0.076387\n",
      "382      3             -0.012449            -0.039607\n",
      "383      2             -0.039544            -0.004483\n",
      "384      5              0.008325             0.046420\n",
      "385      2              0.018780            -0.000138\n",
      "\n",
      "[242 rows x 3 columns]      Group  proportion_diff_depr  proportion_diff_anx\n",
      "1        4             -0.094475            -0.086865\n",
      "2        8             -0.068694            -0.081373\n",
      "3        1              0.001539             0.036491\n",
      "6        8              0.062142            -0.010602\n",
      "15       4             -0.074480            -0.121045\n",
      "..     ...                   ...                  ...\n",
      "371      1             -0.034818            -0.032056\n",
      "376      4             -0.045055            -0.015276\n",
      "380      8             -0.087428            -0.110161\n",
      "381      4              0.087377             0.060305\n",
      "386      4             -0.043055            -0.034761\n",
      "\n",
      "[145 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "#Here we choose which features to use\n",
    "#here we make a train and holdout set. We keep groups seperated in training/holdout\n",
    "#so there is no data leakage from the groups\n",
    "\n",
    "#datasets for features and targets\n",
    "X = df.iloc[:, 5:15].drop(['negative','positive'], axis=1)\n",
    "y = df[['Group','proportion_diff_depr', 'proportion_diff_anx']]\n",
    "groups = df[['Group']]\n",
    "#print(groups)\n",
    "\n",
    "gss = GroupShuffleSplit(n_splits = 2, train_size = .7, random_state = 42)\n",
    "    \n",
    "#train/holdout-split stratified by target\n",
    "for train_idx, holdout_idx in gss.split(X, y, groups):\n",
    "    X_train = X.iloc[train_idx, :]\n",
    "    y_train = y.iloc[train_idx, :]\n",
    "    X_holdout = X.iloc[holdout_idx, :]\n",
    "    y_holdout = y.iloc[holdout_idx, :]\n",
    "\n",
    "print(X_train, X_holdout, y_train, y_holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "96f18ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we save the splits so we can plot them in R later\n",
    "#X_train.to_csv('Data/lexicon_analysis_performance/VAD_raw_scores_X_train.csv')\n",
    "#X_holdout.to_csv('Data/lexicon_analysis_performance/VAD_raw_scores_X_holdout.csv')\n",
    "#y_train.to_csv('Data/lexicon_analysis_performance/VAD_raw_scores_y_train.csv')\n",
    "#y_holdout.to_csv('Data/lexicon_analysis_performance/VAD_raw_scores_y_holdout.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc18623e",
   "metadata": {},
   "source": [
    "# Regression Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ffeb9085",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining function for permutation test for feature importance\n",
    "def permutation_importance_test(features,target):\n",
    "    r = permutation_importance(best_model,\n",
    "                               features,\n",
    "                               target,\n",
    "                               n_repeats=100,\n",
    "                               scoring = 'r2',\n",
    "                               n_jobs=-1,\n",
    "                               random_state=42)\n",
    "    return(r.importances_mean, r.importances_std, r.importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "715f2c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******Start Iteration for Target proportion_diff_depr*******\n",
      "Baseline Model Completed for target proportion_diff_depr\n",
      "Gridsearch before Feature Selection Completed for target proportion_diff_depr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-10-17 16:18:05] Features: 1/7 -- score: 0.01849533694229888[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-10-17 16:18:05] Features: 2/7 -- score: 0.012195244497252577[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-10-17 16:18:05] Features: 3/7 -- score: -0.0009228548126353431[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-10-17 16:18:05] Features: 4/7 -- score: -0.012500972119103037[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-10-17 16:18:05] Features: 5/7 -- score: -0.028711244901056098[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-10-17 16:18:05] Features: 6/7 -- score: -0.036796286488224486[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-10-17 16:18:05] Features: 7/7 -- score: -0.058380604230361"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Selection Completed for target proportion_diff_depr\n",
      "Gridsearch after Feature Selection Completed for target proportion_diff_depr\n",
      "Adaboost and Bagging Completed for target proportion_diff_depr\n",
      "Earlystop Completed for target proportion_diff_depr\n",
      "feature_selection_model\n",
      "Fitting Best Model on Holdout Set Completed target proportion_diff_depr\n",
      "******Start Iteration for Target proportion_diff_anx*******\n",
      "Baseline Model Completed for target proportion_diff_anx\n",
      "Gridsearch before Feature Selection Completed for target proportion_diff_anx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-10-17 16:18:09] Features: 1/7 -- score: 0.03222354686784048[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-10-17 16:18:09] Features: 2/7 -- score: 0.04384159939343033[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-10-17 16:18:09] Features: 3/7 -- score: 0.04140314070689919[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-10-17 16:18:09] Features: 4/7 -- score: 0.0353642885511831[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-10-17 16:18:10] Features: 5/7 -- score: 0.02811048429198366[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "\n",
      "[2022-10-17 16:18:10] Features: 6/7 -- score: 0.01855909807492624[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Selection Completed for target proportion_diff_anx\n",
      "Gridsearch after Feature Selection Completed for target proportion_diff_anx\n",
      "Adaboost and Bagging Completed for target proportion_diff_anx\n",
      "Earlystop Completed for target proportion_diff_anx\n",
      "feature_selection_model\n",
      "Fitting Best Model on Holdout Set Completed target proportion_diff_anx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[2022-10-17 16:18:10] Features: 7/7 -- score: -0.0007369389762936329"
     ]
    }
   ],
   "source": [
    "#defining empty pandas dataframe\n",
    "dataframe = pd.DataFrame(columns = ['target',\n",
    "                                    'feature_names',\n",
    "                                    'baseline_score',\n",
    "                                    'baseline_std_dev',\n",
    "                                    'baseline_std_error',\n",
    "                                    'penalty_before_fs',\n",
    "                                    'regurilization_strength_before_fs',\n",
    "                                    'l1ratio_before_fs',\n",
    "                                    'penalty_score_before_fs',\n",
    "                                    'penalty_std_dev_before_fs',\n",
    "                                    'fs_score',\n",
    "                                    'fs_std_dev',\n",
    "                                    'fs_std_error',\n",
    "                                    'penalty_after_fs',\n",
    "                                    'regurilization_strength_after_fs',\n",
    "                                    'l1ratio_after_fs',\n",
    "                                    'penalty_score_after_fs',\n",
    "                                    'penalty_std_dev_after_fs',\n",
    "                                    'boost_score',\n",
    "                                    'boost_std_dev',\n",
    "                                    'boost_std_error',\n",
    "                                    'bag_score',\n",
    "                                    'bag_std_dev',\n",
    "                                    'bag_std_error',\n",
    "                                    'earlystop_score',\n",
    "                                    'earlystop_std_dev',\n",
    "                                    'earlystop_std_error',\n",
    "                                    'best_model_name',\n",
    "                                    'best_model_train_r2_cv',\n",
    "                                    'best_model_train_r2',\n",
    "                                    'best_model_holdout_r2',\n",
    "                                    'best_model_coef',\n",
    "                                    'best_model_intercept',\n",
    "                                    'predicted_values',\n",
    "                                    'FI_mean_train',\n",
    "                                    'FI_std_train',\n",
    "                                    'FI_mean_holdout',\n",
    "                                    'FI_std_holdout'])\n",
    "\n",
    "#setting up variables for loop and appending\n",
    "columns = list(dataframe)\n",
    "data = []\n",
    "\n",
    "groups_train = y_train['Group']\n",
    "groups_holdout = y_holdout['Group']\n",
    "cv = GroupKFold(n_splits=5)\n",
    "\n",
    "#LOOP\n",
    "#loop over targets\n",
    "\n",
    "#looping over targets\n",
    "for target in (range(1,3)):\n",
    "    y_train_target = y_train.iloc[:, target]\n",
    "    y_name = y_train_target.name\n",
    "    y_holdout_target = y_holdout.iloc[:, target]\n",
    "\n",
    "    print('******Start Iteration for Target %s*******' %(y_name))\n",
    "\n",
    "\n",
    "    #-------------------------Baseline Model-----------------------------\n",
    "\n",
    "    #Creating baseline model without any penalty\n",
    "    baseline = LinearRegression(n_jobs = -1)\n",
    "\n",
    "    #Evaluate by cv\n",
    "    baseline_cv = cross_val_score(baseline,\n",
    "                               X_train,\n",
    "                               y_train_target,\n",
    "                               scoring = 'r2', \n",
    "                               cv=cv, \n",
    "                               groups = groups_train,\n",
    "                               n_jobs=-1,\n",
    "                               error_score='raise')\n",
    "\n",
    "    #Logging Scores\n",
    "    baseline_score = baseline_cv.mean()\n",
    "    baseline_std_dev = baseline_cv.std()\n",
    "    baseline_std_error = sem(baseline_cv)\n",
    "\n",
    "    print('Baseline Model Completed for target %s' %(y_name)) \n",
    "\n",
    "\n",
    "    #-------------------GRIDSEARCH L1/L2/Elasticnet--------------------------\n",
    "    #-------------------(Before feature selection)-------------------------\n",
    "    #-------------------Another way of feature selection-----------------------\n",
    "\n",
    "    #Standard Scaling \n",
    "    #We fit the scaler only on the training data and standardise\n",
    "    #both training and test features (not target!) with that scaler\n",
    "    sc = StandardScaler()\n",
    "    X_train_sc = sc.fit_transform(X_train)\n",
    "    X_holdout_sc = sc.transform(X_holdout)\n",
    "\n",
    "    # Defining penalties and value of inverse of regurilization strength\n",
    "    # smaller values of C specify stronger regurilization.\n",
    "    #also define l1ratio in case elasticnet is chosen \n",
    "    penalty = ['l1', 'l2', 'elasticnet', 'none']\n",
    "    alpha = np.logspace(-3,3,7)\n",
    "    l1_ratio = np.linspace(0,1,11)\n",
    "\n",
    "    #defining a dictionary parameters to search\n",
    "    parameters = [{\"alpha\":np.logspace(-3,3,7), \n",
    "                   \"penalty\": penalty,\n",
    "                   'l1_ratio': l1_ratio}]\n",
    "\n",
    "    #making the gridsearch and fitting features and target\n",
    "    kep = GridSearchCV(\n",
    "        estimator = SGDRegressor(random_state=42),\n",
    "                    param_grid = parameters,\n",
    "                    n_jobs = -1,\n",
    "                    scoring = 'r2', \n",
    "                    cv=cv,\n",
    "                    refit = True).fit(X_train_sc, y_train_target, groups = groups_train)\n",
    "\n",
    "    #logging penalty, regurilization strength and best score\n",
    "    penalty_before_fs = kep.best_estimator_.get_params()['penalty']\n",
    "    regurilization_strength_before_fs = kep.best_estimator_.get_params()['alpha']\n",
    "    l1ratio_before_fs = kep.best_estimator_.get_params()['l1_ratio']\n",
    "    penalty_score_before_fs = kep.best_score_\n",
    "    penalty_std_dev_before_fs = kep.cv_results_['std_test_score'][kep.best_index_]\n",
    "    gridsearch_best_model_before_fs = kep.best_estimator_\n",
    "\n",
    "    print('Gridsearch before Feature Selection Completed for target %s' %(y_name)) \n",
    "\n",
    "    #-------------------------Feature Selection-----------------------\n",
    "    #making base estimator logistic regression with no penalty\n",
    "    base = LinearRegression(n_jobs = -1)\n",
    "\n",
    "    #making the forward selection with cv\n",
    "    forward = SequentialFeatureSelector(\n",
    "    base,\n",
    "    k_features = 'best',\n",
    "    cv = 5,\n",
    "    forward = True, \n",
    "    floating = False,\n",
    "    scoring = 'r2', \n",
    "    verbose = 2, \n",
    "    n_jobs = -1 \n",
    "    ).fit(X_train, y_train_target)\n",
    "\n",
    "    #saving forward-output to a dataframe\n",
    "    le = pd.DataFrame.from_dict(forward.get_metric_dict()).T\n",
    "\n",
    "    #finding the index of the best combination of features\n",
    "    max_index = np.argmax(le.avg_score)\n",
    "\n",
    "    #saving metrics from the best combination\n",
    "    feature_names = le.iloc[max_index,3]\n",
    "    fs_score = le.iloc[max_index,2]\n",
    "    fs_std_dev = le.iloc[max_index, 5]\n",
    "    fs_std_error = le.iloc[max_index, 6]\n",
    "\n",
    "    #Choosing best features in X_train and use that in the rest of the loop\n",
    "    feature_names_list = list(feature_names)\n",
    "    X_train_after_fs = X_train[[c for c in X_train.columns if c in feature_names_list]]\n",
    "    #defining holdout sets after feature selection\n",
    "    X_holdout_after_fs = X_holdout[[c for c in X_holdout.columns if c in feature_names_list]]\n",
    "\n",
    "    print('Feature Selection Completed for target %s' %(y_name))\n",
    "\n",
    "    #------------------GRIDSEARCH L1/L2/Elasticnet-----------------------\n",
    "    #------------------(After feature selection)-------------------------\n",
    "\n",
    "    #Standard Scaling \n",
    "    #We fit the scaler only on the training data and standardise\n",
    "    #both training and test features (not target!) with that scaler\n",
    "    sc = StandardScaler()\n",
    "    X_train_after_fs_sc = sc.fit_transform(X_train_after_fs)\n",
    "    X_holdout_after_fs_sc = sc.transform(X_holdout_after_fs)\n",
    "\n",
    "    # Defining penalties and value of inverse of regurilization strength\n",
    "    # smaller values of C specify stronger regurilization.\n",
    "    #also define l1ratio in case elasticnet is chosen \n",
    "    penalty = ['l1', 'l2', 'elasticnet', 'none']\n",
    "    alpha = np.logspace(-3,3,7)\n",
    "    l1_ratio = np.linspace(0,1,11)\n",
    "\n",
    "    #defining a dictionary parameters to search\n",
    "    parameters = [{\"alpha\":np.logspace(-3,3,7), \n",
    "                   \"penalty\": penalty,\n",
    "                   'l1_ratio': l1_ratio}]\n",
    "\n",
    "    #making the gridsearch and fitting features and target\n",
    "    kep = GridSearchCV(\n",
    "        estimator = SGDRegressor(random_state=42),\n",
    "                    param_grid = parameters,\n",
    "                    n_jobs = -1,\n",
    "                    scoring = 'r2', \n",
    "                    cv=cv,\n",
    "                    refit = True).fit(X_train_after_fs_sc, y_train_target, groups = groups_train)\n",
    "\n",
    "    #logging penalty, regurilization strength and best score\n",
    "    penalty_after_fs = kep.best_estimator_.get_params()['penalty']\n",
    "    regurilization_strength_after_fs = kep.best_estimator_.get_params()['alpha']\n",
    "    l1ratio_after_fs = kep.best_estimator_.get_params()['l1_ratio']\n",
    "    penalty_score_after_fs = kep.best_score_\n",
    "    penalty_std_dev_after_fs = kep.cv_results_['std_test_score'][kep.best_index_]\n",
    "    gridsearch_best_model_after_fs = kep.best_estimator_\n",
    "\n",
    "    print('Gridsearch after Feature Selection Completed for target %s' %(y_name))\n",
    "\n",
    "    #-----------------------Adaboost and Bagging------------------------------\n",
    "    #These three regurilization techniques apply the penalty selected\n",
    "    #in the gridsearch above\n",
    "\n",
    "    #AdaBoost\n",
    "    boost = AdaBoostRegressor(base_estimator = gridsearch_best_model_after_fs,\n",
    "                                      random_state=42)\n",
    "\n",
    "    #Bagging\n",
    "    bag = BaggingRegressor(base_estimator = gridsearch_best_model_after_fs,\n",
    "                                     random_state=42,\n",
    "                                     n_jobs = -1)\n",
    "\n",
    "    #Evaluate Adaboost by cv\n",
    "    boost_cv = cross_val_score(boost,\n",
    "                               X_train_after_fs_sc,\n",
    "                               y_train_target,\n",
    "                               scoring = 'r2',\n",
    "                               cv=cv, \n",
    "                               groups = groups_train,\n",
    "                               n_jobs=-1,\n",
    "                               error_score='raise')\n",
    "\n",
    "    #Evaluate bagging by cv\n",
    "    bag_cv = cross_val_score(bag,\n",
    "                               X_train_after_fs_sc,\n",
    "                               y_train_target,\n",
    "                               scoring = 'r2',\n",
    "                               cv=cv, \n",
    "                               groups = groups_train,\n",
    "                               n_jobs=-1,\n",
    "                               error_score='raise')\n",
    "\n",
    "    #logging scores\n",
    "    boost_score = boost_cv.mean()\n",
    "    boost_std_dev = boost_cv.std()\n",
    "    boost_std_error = sem(boost_cv)\n",
    "\n",
    "    bag_score = bag_cv.mean()\n",
    "    bag_std_dev = bag_cv.std()\n",
    "    bag_std_error = sem(bag_cv)\n",
    "\n",
    "    print('Adaboost and Bagging Completed for target %s' %(y_name))\n",
    "\n",
    "\n",
    "    #----------------------------Earlystopping---------------------\n",
    "\n",
    "    #base model for earlystop\n",
    "    earlystop =  SGDRegressor( penalty=str(penalty_after_fs), \n",
    "                               alpha=regurilization_strength_after_fs,\n",
    "                               l1_ratio=l1ratio_after_fs,\n",
    "                               verbose=1,\n",
    "                               early_stopping=True,\n",
    "                               validation_fraction=0.2)\n",
    "\n",
    "    #Evaluate earlystop by cv\n",
    "    earlystop_cv = cross_val_score(earlystop,\n",
    "                               X_train_after_fs_sc,\n",
    "                               y_train_target,\n",
    "                               scoring= 'r2',\n",
    "                               cv=cv, \n",
    "                               groups = groups_train,\n",
    "                               n_jobs=-1,\n",
    "                               error_score='raise')\n",
    "\n",
    "\n",
    "    earlystop_score = earlystop_cv.mean()\n",
    "    earlystop_std_dev = earlystop_cv.std()\n",
    "    earlystop_std_error = sem(earlystop_cv)\n",
    "\n",
    "    print('Earlystop Completed for target %s' %(y_name))\n",
    "\n",
    "    #-----------------------------Model Evaluation---------------------------\n",
    "\n",
    "    #selecting the best model and its name\n",
    "    scorings = (baseline_score, penalty_score_before_fs, fs_score,\n",
    "              penalty_score_after_fs, boost_score, bag_score, earlystop_score)\n",
    "    model_names = ('baseline_model', 'penalty_model_before_fs', 'feature_selection_model',\n",
    "                   'penalty_model_after_fs', 'boost_model', 'bag_model', 'earlystop_model')\n",
    "    index_max = scorings. index(max(scorings)) \n",
    "    best_model_name = model_names[index_max]\n",
    "    best_model_train_r2_cv = scorings[index_max]\n",
    "    print(best_model_name)\n",
    "\n",
    "    #Defining the best model\n",
    "    if index_max == 0:\n",
    "        best_model = LinearRegression(n_jobs = -1)\n",
    "\n",
    "    if index_max == 1:\n",
    "        best_model = gridsearchbest_model_before_fs                                             \n",
    "\n",
    "    elif index_max == 2:\n",
    "        best_model = LinearRegression(n_jobs = -1)\n",
    "\n",
    "    elif index_max == 3:\n",
    "        best_model = gridsearch_best_model_after_fs\n",
    "\n",
    "    elif index_max == 4:\n",
    "        best_model = AdaBoostRegressor(base_estimator = gridsearch_best_model_after_fs,\n",
    "                                      random_state=42)\n",
    "\n",
    "    elif index_max == 5:\n",
    "        best_model = BaggingRegressor(base_estimator = gridsearch_best_model_after_fs,\n",
    "                                     random_state=42,\n",
    "                                     n_jobs = -1)\n",
    "    elif index_max == 6:\n",
    "        best_model =  SGDRegressor(penalty=str(penalty_after_fs), \n",
    "                                   alpha=regurilization_strength_after_fs,\n",
    "                                   l1_ratio=l1ratio_after_fs,\n",
    "                                   verbose=1,\n",
    "                                   early_stopping=True,\n",
    "                                   validation_fraction=0.2)\n",
    "\n",
    "   #Get fit, score, coefficients, intercept and apply permutation test on\n",
    "   #the best model based on whether it is before or after feature selection or with scaled features\n",
    "\n",
    "    #using features before feature selection (non-scaled)\n",
    "    if index_max == 0:\n",
    "        best_model = best_model.fit(X_train, y_train_target)\n",
    "        best_model_train_r2 = best_model.score(X_train, y_train_target)\n",
    "        best_model_holdout_r2 = best_model.score(X_holdout, y_holdout_target)\n",
    "        predicted_values = best_model.predict(X_holdout)\n",
    "        \n",
    "        #permutation feature importance for train and holdout\n",
    "        FI_mean_train, FI_std_train, FI_importances_train = permutation_importance_test(\n",
    "        X_train, y_train_target)\n",
    "        FI_mean_holdout, FI_std_holdout, FI_importances_holdout = permutation_importance_test(\n",
    "        X_holdout, y_holdout_target)\n",
    "\n",
    "        \n",
    "    #using features before feature selection and scaled\n",
    "    elif index_max == 1:\n",
    "        best_model = best_model.fit(X_train_sc, y_train_target)\n",
    "        best_model_train_r2 = best_model.score(X_train_sc, y_train_target)\n",
    "        best_model_holdout_r2 = best_model.score(X_holdout_sc, y_holdout_target)\n",
    "        predicted_values = best_model.predict(X_holdout_sc)\n",
    "        \n",
    "        #permutation feature importance for train and holdout\n",
    "        FI_mean_train, FI_std_train, FI_importances_train = permutation_importance_test(\n",
    "        X_train_sc, y_train_target)\n",
    "        FI_mean_holdout, FI_std_holdout, FI_importances_holdout = permutation_importance_test(\n",
    "        X_holdout_sc, y_holdout_target)\n",
    "\n",
    "\n",
    "    #using features after feature selection (non-scaled)\n",
    "    elif index_max == 2:\n",
    "        best_model = best_model.fit(X_train_after_fs, y_train_target)\n",
    "        best_model_train_r2 = best_model.score(X_train_after_fs, y_train_target)\n",
    "        best_model_holdout_r2 = best_model.score(X_holdout_after_fs, y_holdout_target)\n",
    "        predicted_values = best_model.predict(X_holdout_after_fs)\n",
    "        \n",
    "        #permutation feature importance for train and holdout\n",
    "        FI_mean_train, FI_std_train, FI_importances_train = permutation_importance_test(\n",
    "        X_train_after_fs, y_train_target)\n",
    "        FI_mean_holdout, FI_std_holdout, FI_importances_holdout = permutation_importance_test(\n",
    "        X_holdout_after_fs, y_holdout_target)\n",
    "\n",
    "\n",
    "    #using features after feature selection and scaled   \n",
    "    elif index_max in (3,4,5,6):\n",
    "        best_model = best_model.fit(X_train_after_fs_sc, y_train_target)\n",
    "        best_model_train_r2 = best_model.score(X_train_after_fs_sc, y_train_target)\n",
    "        best_model_holdout_r2 = best_model.score(X_holdout_after_fs_sc, y_holdout_target)\n",
    "        predicted_values = best_model.predict(X_holdout_after_fs_sc)\n",
    "        \n",
    "        #permutation feature importance for train and holdout\n",
    "        FI_mean_train, FI_std_train, FI_importances_train = permutation_importance_test(\n",
    "        X_train_after_fs_sc, y_train_target)\n",
    "        FI_mean_holdout, FI_std_holdout, FI_importances_holdout = permutation_importance_test(\n",
    "        X_holdout_after_fs_sc, y_holdout_target)\n",
    "        \n",
    "    best_model_coef = best_model.coef_\n",
    "    best_model_intercept = best_model.intercept_\n",
    "\n",
    "    print('Fitting Best Model on Holdout Set Completed target %s' %(y_name))\n",
    "\n",
    "\n",
    "   #--------------------------Saving output-----------------------------\n",
    "\n",
    "    #defining outputs as list\n",
    "    output = [y_name,\n",
    "              feature_names,\n",
    "              baseline_score,\n",
    "              baseline_std_dev,\n",
    "              baseline_std_error,\n",
    "              penalty_before_fs,\n",
    "              regurilization_strength_before_fs,\n",
    "              l1ratio_before_fs,\n",
    "              penalty_score_before_fs,\n",
    "              penalty_std_dev_before_fs,\n",
    "              fs_score,\n",
    "              fs_std_dev,\n",
    "              fs_std_error,\n",
    "              penalty_after_fs,\n",
    "              regurilization_strength_after_fs,\n",
    "              l1ratio_after_fs,\n",
    "              penalty_score_after_fs,\n",
    "              penalty_std_dev_after_fs,\n",
    "              boost_score,\n",
    "              boost_std_dev,\n",
    "              boost_std_error,\n",
    "              bag_score,\n",
    "              bag_std_dev,\n",
    "              bag_std_error,\n",
    "              earlystop_score,\n",
    "              earlystop_std_dev,\n",
    "              earlystop_std_error,\n",
    "              best_model_name,\n",
    "              best_model_train_r2_cv,\n",
    "              best_model_train_r2,\n",
    "              best_model_holdout_r2,\n",
    "              best_model_coef,\n",
    "              best_model_intercept,\n",
    "              predicted_values,\n",
    "              FI_mean_train,\n",
    "              FI_std_train,\n",
    "              FI_mean_holdout,\n",
    "              FI_std_holdout]\n",
    "\n",
    "    #turning outputs into zipped\n",
    "    zipped = zip(columns, output)\n",
    "    #turning zipped into dictionary\n",
    "    output_dict = dict(zipped)\n",
    "    #appending to our data\n",
    "    data.append(output_dict)\n",
    "\n",
    "\n",
    "#finally (phew) appending data to dataframe\n",
    "dataframe = dataframe.append(data, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "993433fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataframe.to_csv('Data/lexicon_analysis_performance/emotion_raw_scores_negposremoved.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4cc8f6b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>feature_names</th>\n",
       "      <th>baseline_score</th>\n",
       "      <th>baseline_std_dev</th>\n",
       "      <th>baseline_std_error</th>\n",
       "      <th>penalty_before_fs</th>\n",
       "      <th>regurilization_strength_before_fs</th>\n",
       "      <th>l1ratio_before_fs</th>\n",
       "      <th>penalty_score_before_fs</th>\n",
       "      <th>penalty_std_dev_before_fs</th>\n",
       "      <th>...</th>\n",
       "      <th>best_model_train_r2_cv</th>\n",
       "      <th>best_model_train_r2</th>\n",
       "      <th>best_model_holdout_r2</th>\n",
       "      <th>best_model_coef</th>\n",
       "      <th>best_model_intercept</th>\n",
       "      <th>predicted_values</th>\n",
       "      <th>FI_mean_train</th>\n",
       "      <th>FI_std_train</th>\n",
       "      <th>FI_mean_holdout</th>\n",
       "      <th>FI_std_holdout</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>proportion_diff_depr</td>\n",
       "      <td>(fear,)</td>\n",
       "      <td>-0.190664</td>\n",
       "      <td>0.248601</td>\n",
       "      <td>0.124300</td>\n",
       "      <td>l2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.158259</td>\n",
       "      <td>0.241866</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018495</td>\n",
       "      <td>0.040898</td>\n",
       "      <td>0.015701</td>\n",
       "      <td>[-0.03456029007539063]</td>\n",
       "      <td>-0.001969</td>\n",
       "      <td>[-0.0019692955104200103, -0.001969295510420010...</td>\n",
       "      <td>[0.08137222440482281]</td>\n",
       "      <td>[0.028039688695025527]</td>\n",
       "      <td>[0.08014152049262334]</td>\n",
       "      <td>[0.02813979265417173]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>proportion_diff_anx</td>\n",
       "      <td>(disgust, sadness)</td>\n",
       "      <td>-0.124430</td>\n",
       "      <td>0.210671</td>\n",
       "      <td>0.105336</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.095050</td>\n",
       "      <td>0.174047</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043842</td>\n",
       "      <td>0.086096</td>\n",
       "      <td>0.086744</td>\n",
       "      <td>[-0.04375844738884718, -0.036668547786558356]</td>\n",
       "      <td>0.003228</td>\n",
       "      <td>[0.0032277562033045572, 0.0032277562033045572,...</td>\n",
       "      <td>[0.06074508029805657, 0.05220358844218828]</td>\n",
       "      <td>[0.020374982585213128, 0.02087310630175312]</td>\n",
       "      <td>[0.05895326952970903, 0.05195713957306466]</td>\n",
       "      <td>[0.02277187167354429, 0.022421899551549135]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 target       feature_names  baseline_score  baseline_std_dev  \\\n",
       "0  proportion_diff_depr             (fear,)       -0.190664          0.248601   \n",
       "1   proportion_diff_anx  (disgust, sadness)       -0.124430          0.210671   \n",
       "\n",
       "   baseline_std_error penalty_before_fs  regurilization_strength_before_fs  \\\n",
       "0            0.124300                l2                               1.00   \n",
       "1            0.105336        elasticnet                               0.01   \n",
       "\n",
       "   l1ratio_before_fs  penalty_score_before_fs  penalty_std_dev_before_fs  ...  \\\n",
       "0                0.0                -0.158259                   0.241866  ...   \n",
       "1                0.2                -0.095050                   0.174047  ...   \n",
       "\n",
       "   best_model_train_r2_cv  best_model_train_r2  best_model_holdout_r2  \\\n",
       "0                0.018495             0.040898               0.015701   \n",
       "1                0.043842             0.086096               0.086744   \n",
       "\n",
       "                                 best_model_coef  best_model_intercept  \\\n",
       "0                         [-0.03456029007539063]             -0.001969   \n",
       "1  [-0.04375844738884718, -0.036668547786558356]              0.003228   \n",
       "\n",
       "                                    predicted_values  \\\n",
       "0  [-0.0019692955104200103, -0.001969295510420010...   \n",
       "1  [0.0032277562033045572, 0.0032277562033045572,...   \n",
       "\n",
       "                                FI_mean_train  \\\n",
       "0                       [0.08137222440482281]   \n",
       "1  [0.06074508029805657, 0.05220358844218828]   \n",
       "\n",
       "                                  FI_std_train  \\\n",
       "0                       [0.028039688695025527]   \n",
       "1  [0.020374982585213128, 0.02087310630175312]   \n",
       "\n",
       "                              FI_mean_holdout  \\\n",
       "0                       [0.08014152049262334]   \n",
       "1  [0.05895326952970903, 0.05195713957306466]   \n",
       "\n",
       "                                FI_std_holdout  \n",
       "0                        [0.02813979265417173]  \n",
       "1  [0.02277187167354429, 0.022421899551549135]  \n",
       "\n",
       "[2 rows x 38 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
